================================================================================
BERT DIAGNOSIS SIMILARITY SCORE DISTRIBUTION ANALYSIS
================================================================================

SECTION 1: ALL-PAIRWISE DIAGNOSIS SIMILARITIES
------------------------------------------------------------
Each model embeds all unique diagnosis descriptions, then
computes cosine similarity for every pair (excluding self-pairs).

Model: Bio_ClinicalBERT
  N = 10440
  Min    = 0.6454
  Max    = 0.9919
  Mean   = 0.8348
  Median = 0.8371
  Std    = 0.0450
  P5     = 0.7567
  P25    = 0.8067
  P75    = 0.8651
  P95    = 0.9027
  % >= 0.6 = 100.00%
  % >= 0.7 = 99.55%
  % >= 0.8 = 79.26%
  % >= 0.9 = 5.58%
  % >= 1.0 = 0.00%

Model: BiomedBERT
  N = 10440
  Min    = 0.7246
  Max    = 0.9982
  Mean   = 0.9282
  Median = 0.9341
  Std    = 0.0303
  P5     = 0.8697
  P25    = 0.9181
  P75    = 0.9470
  P95    = 0.9625
  % >= 0.6 = 100.00%
  % >= 0.7 = 100.00%
  % >= 0.8 = 99.32%
  % >= 0.9 = 87.62%
  % >= 1.0 = 0.00%

Model: BlueBERT
  N = 10440
  Min    = 0.4810
  Max    = 0.9905
  Mean   = 0.7170
  Median = 0.7176
  Std    = 0.0652
  P5     = 0.6111
  P25    = 0.6742
  P75    = 0.7591
  P95    = 0.8204
  % >= 0.6 = 96.35%
  % >= 0.7 = 60.98%
  % >= 0.8 = 9.02%
  % >= 0.9 = 0.59%
  % >= 1.0 = 0.00%


SECTION 2: PER-PATIENT MAX SIMILARITIES
------------------------------------------------------------
For each pair of patients (A, B), compute the MAX cosine
similarity across all (gt_diag_A, pred_diag_B) pairs.
This is what get_diagnosis_similarity_by_description_max() returns
and what determines TP/FP at each threshold.

Model: Bio_ClinicalBERT
  N = 16512
  Min    = 0.7218
  Max    = 1.0000
  Mean   = 0.8586
  Median = 0.8585
  Std    = 0.0410
  P5     = 0.7966
  P25    = 0.8325
  P75    = 0.8828
  P95    = 0.9223
  % >= 0.6 = 100.00%
  % >= 0.7 = 100.00%
  % >= 0.8 = 93.81%
  % >= 0.9 = 11.63%
  % >= 1.0 = 1.49%

Model: BiomedBERT
  N = 16512
  Min    = 0.8698
  Max    = 1.0000
  Mean   = 0.9447
  Median = 0.9447
  Std    = 0.0168
  P5     = 0.9183
  P25    = 0.9337
  P75    = 0.9554
  P95    = 0.9690
  % >= 0.6 = 100.00%
  % >= 0.7 = 100.00%
  % >= 0.8 = 100.00%
  % >= 0.9 = 99.71%
  % >= 1.0 = 1.62%

Model: BlueBERT
  N = 16512
  Min    = 0.5684
  Max    = 1.0000
  Mean   = 0.7565
  Median = 0.7522
  Std    = 0.0624
  P5     = 0.6660
  P25    = 0.7163
  P75    = 0.7880
  P95    = 0.8490
  % >= 0.6 = 99.96%
  % >= 0.7 = 84.16%
  % >= 0.8 = 18.87%
  % >= 0.9 = 2.47%
  % >= 1.0 = 1.31%


Diagnosis Count Per Patient:
  Min  = 1
  Max  = 3
  Mean = 1.74
  Total unique diagnoses = 145
  Total patients = 129
  Total patient pairs = 16512


Verification: numpy vs cython_utils.cosine_similarity()
  Bio_ClinicalBERT: max absolute difference = 2.11e-07
  BiomedBERT: max absolute difference = 8.58e-07
  BlueBERT: max absolute difference = 1.98e-07


SECTION 3: INTERPRETATION
------------------------------------------------------------

Key Findings:

1. EMBEDDING SPACE COMPACTNESS
   Bio_ClinicalBERT: mean pairwise similarity = 0.8348, std = 0.0450
   BiomedBERT: mean pairwise similarity = 0.9282, std = 0.0303
   BlueBERT: mean pairwise similarity = 0.7170, std = 0.0652
   Biomedical BERT models embed medical diagnosis text into a
   relatively narrow region of the embedding space, producing
   high baseline similarities even between unrelated diagnoses.

2. MAX OPERATOR AMPLIFICATION
   Bio_ClinicalBERT: pairwise mean = 0.8348 -> per-patient MAX mean = 0.8586
   BiomedBERT: pairwise mean = 0.9282 -> per-patient MAX mean = 0.9447
   BlueBERT: pairwise mean = 0.7170 -> per-patient MAX mean = 0.7565
   With 1.7 diagnoses per patient on average,
   the Cartesian product contains ~3 pairs.
   Taking the MAX over this product dramatically inflates the
   effective similarity, pushing nearly all pairs above 0.6.

3. THRESHOLD SATURATION
   Bio_ClinicalBERT:
     >= 0.6: 100.00%
     >= 0.7: 100.00%
     >= 0.8: 93.81%
     >= 0.9: 11.63%
     >= 1.0: 1.49%
   BiomedBERT:
     >= 0.6: 100.00%
     >= 0.7: 100.00%
     >= 0.8: 100.00%
     >= 0.9: 99.71%
     >= 1.0: 1.62%
   BlueBERT:
     >= 0.6: 99.96%
     >= 0.7: 84.16%
     >= 0.8: 18.87%
     >= 0.9: 2.47%
     >= 1.0: 1.31%

   This explains why all models achieve perfect F1 at 0.6:
   virtually every patient pair has MAX similarity >= 0.6.
   The evaluation metric is saturated and cannot discriminate
   between models or meaningfully compare against BioSentVec.

4. IMPLICATIONS
   - The current evaluation methodology (MAX over Cartesian product
     of diagnosis descriptions) is too lenient for BERT models.
   - Consider alternative evaluation strategies:
     a) Use MEAN instead of MAX over diagnosis pairs
     b) Use exact/partial DRG code matching
     c) Raise thresholds significantly (e.g., 0.95+)
     d) Use a different similarity metric that better
        discriminates in compact embedding spaces

================================================================================
